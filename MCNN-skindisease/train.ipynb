{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Skin Disease Analyzer on MCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_width, img_height = 200, 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_dir = \"dataset/train\"\n",
    "validation_data_dir = \"dataset/test\"\n",
    "nb_train_samples = 3578\n",
    "nb_validation_samples = 998\n",
    "epochs = 112\n",
    "batch_size = 32 #16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if K.image_data_format() == 'channels_first':\n",
    "    input_shape = (3, img_width, img_height)\n",
    "else:\n",
    "    input_shape = (img_width, img_height, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rescale = 1. / 255,\n",
    "    shear_range = 0.2,\n",
    "    zoom_range= 0.2,\n",
    "    horizontal_flip= True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1. / 255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3578 images belonging to 4 classes.\n",
      "Found 998 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size= (img_width, img_height),\n",
    "    batch_size= batch_size,\n",
    "    class_mode= 'categorical')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    validation_data_dir,\n",
    "    target_size= (img_width, img_height),\n",
    "    batch_size= batch_size,\n",
    "    class_mode= 'categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\mr. fr3aky\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 198, 198, 32)      896       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 198, 198, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 99, 99, 32)        0         \n",
      "=================================================================\n",
      "Total params: 896\n",
      "Trainable params: 896\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:From c:\\users\\mr. fr3aky\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 198, 198, 32)      896       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 198, 198, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 99, 99, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 97, 97, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 97, 97, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 48, 48, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 46, 46, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 46, 46, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 23, 23, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 23, 23, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 21, 21, 128)       73856     \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 21, 21, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 10, 10, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 10, 10, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 8, 8, 256)         295168    \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 2, 2, 512)         1180160   \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 1, 1, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 4)                 260       \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 2,013,220\n",
      "Trainable params: 2,013,220\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), input_shape = input_shape))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size= (2, 2)))\n",
    "model.summary()\n",
    "\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size= (2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size= (2, 2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(128, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size= (2, 2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(256, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size= (2, 2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(512, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size= (2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(256))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(128))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(4))\n",
    "model.add(Activation('softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss= 'categorical_crossentropy',\n",
    "    optimizer= 'adam',\n",
    "    metrics= ['accuracy'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\mr. fr3aky\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/112\n",
      "111/111 [==============================] - 224s 2s/step - loss: 1.3235 - acc: 0.3356 - val_loss: 1.2626 - val_acc: 0.3417\n",
      "Epoch 2/112\n",
      "111/111 [==============================] - 222s 2s/step - loss: 1.2192 - acc: 0.3942 - val_loss: 1.1472 - val_acc: 0.4586\n",
      "Epoch 3/112\n",
      "111/111 [==============================] - 227s 2s/step - loss: 1.1634 - acc: 0.4548 - val_loss: 1.1279 - val_acc: 0.5052\n",
      "Epoch 4/112\n",
      "111/111 [==============================] - 249s 2s/step - loss: 1.1123 - acc: 0.4941 - val_loss: 1.0791 - val_acc: 0.5228\n",
      "Epoch 5/112\n",
      "111/111 [==============================] - 245s 2s/step - loss: 1.0724 - acc: 0.5203 - val_loss: 1.0424 - val_acc: 0.5807\n",
      "Epoch 6/112\n",
      "111/111 [==============================] - 220s 2s/step - loss: 1.0251 - acc: 0.5633 - val_loss: 0.9806 - val_acc: 0.5807\n",
      "Epoch 7/112\n",
      "111/111 [==============================] - 221s 2s/step - loss: 0.9828 - acc: 0.5953 - val_loss: 1.0836 - val_acc: 0.4845\n",
      "Epoch 8/112\n",
      "111/111 [==============================] - 219s 2s/step - loss: 0.9559 - acc: 0.6086 - val_loss: 0.9752 - val_acc: 0.6046\n",
      "Epoch 9/112\n",
      "111/111 [==============================] - 220s 2s/step - loss: 0.9282 - acc: 0.6184 - val_loss: 0.8986 - val_acc: 0.6398\n",
      "Epoch 10/112\n",
      "111/111 [==============================] - 219s 2s/step - loss: 0.8697 - acc: 0.6585 - val_loss: 0.8316 - val_acc: 0.6718\n",
      "Epoch 11/112\n",
      "111/111 [==============================] - 222s 2s/step - loss: 0.8315 - acc: 0.6686 - val_loss: 0.8562 - val_acc: 0.6718\n",
      "Epoch 12/112\n",
      "111/111 [==============================] - 220s 2s/step - loss: 0.8277 - acc: 0.6816 - val_loss: 0.8263 - val_acc: 0.6801\n",
      "Epoch 13/112\n",
      "111/111 [==============================] - 220s 2s/step - loss: 0.8038 - acc: 0.6931 - val_loss: 0.8975 - val_acc: 0.6636\n",
      "Epoch 14/112\n",
      "111/111 [==============================] - 220s 2s/step - loss: 0.7940 - acc: 0.6973 - val_loss: 0.7773 - val_acc: 0.6863\n",
      "Epoch 15/112\n",
      "111/111 [==============================] - 220s 2s/step - loss: 0.7452 - acc: 0.7258 - val_loss: 0.7402 - val_acc: 0.7226\n",
      "Epoch 16/112\n",
      "111/111 [==============================] - 219s 2s/step - loss: 0.7510 - acc: 0.7121 - val_loss: 0.7475 - val_acc: 0.7112\n",
      "Epoch 17/112\n",
      "111/111 [==============================] - 220s 2s/step - loss: 0.7374 - acc: 0.7181 - val_loss: 0.7320 - val_acc: 0.7360\n",
      "Epoch 18/112\n",
      "111/111 [==============================] - 219s 2s/step - loss: 0.7243 - acc: 0.7289 - val_loss: 0.7727 - val_acc: 0.6884\n",
      "Epoch 19/112\n",
      "111/111 [==============================] - 219s 2s/step - loss: 0.7047 - acc: 0.7348 - val_loss: 0.7072 - val_acc: 0.7195\n",
      "Epoch 20/112\n",
      "111/111 [==============================] - 220s 2s/step - loss: 0.6914 - acc: 0.7490 - val_loss: 0.7757 - val_acc: 0.7153\n",
      "Epoch 21/112\n",
      "111/111 [==============================] - 220s 2s/step - loss: 0.6909 - acc: 0.7424 - val_loss: 0.6515 - val_acc: 0.7350\n",
      "Epoch 22/112\n",
      "111/111 [==============================] - 226s 2s/step - loss: 0.6567 - acc: 0.7585 - val_loss: 0.6568 - val_acc: 0.7526\n",
      "Epoch 23/112\n",
      "111/111 [==============================] - 223s 2s/step - loss: 0.6299 - acc: 0.7694 - val_loss: 0.6326 - val_acc: 0.7671\n",
      "Epoch 24/112\n",
      "111/111 [==============================] - 219s 2s/step - loss: 0.6079 - acc: 0.7764 - val_loss: 0.6741 - val_acc: 0.7402\n",
      "Epoch 25/112\n",
      "111/111 [==============================] - 214s 2s/step - loss: 0.6334 - acc: 0.7677 - val_loss: 0.6416 - val_acc: 0.7578\n",
      "Epoch 26/112\n",
      "111/111 [==============================] - 199s 2s/step - loss: 0.6127 - acc: 0.7752 - val_loss: 0.6397 - val_acc: 0.7360\n",
      "Epoch 27/112\n",
      "111/111 [==============================] - 199s 2s/step - loss: 0.5856 - acc: 0.7807 - val_loss: 0.6359 - val_acc: 0.7598\n",
      "Epoch 28/112\n",
      "111/111 [==============================] - 199s 2s/step - loss: 0.5709 - acc: 0.7896 - val_loss: 0.6701 - val_acc: 0.7433\n",
      "Epoch 29/112\n",
      "111/111 [==============================] - 199s 2s/step - loss: 0.5763 - acc: 0.7903 - val_loss: 0.6746 - val_acc: 0.7402\n",
      "Epoch 30/112\n",
      "111/111 [==============================] - 200s 2s/step - loss: 0.5530 - acc: 0.7920 - val_loss: 0.6113 - val_acc: 0.7609\n",
      "Epoch 31/112\n",
      "111/111 [==============================] - 199s 2s/step - loss: 0.5330 - acc: 0.8015 - val_loss: 0.6389 - val_acc: 0.7516\n",
      "Epoch 32/112\n",
      "111/111 [==============================] - 199s 2s/step - loss: 0.5089 - acc: 0.8130 - val_loss: 0.6097 - val_acc: 0.7723\n",
      "Epoch 33/112\n",
      "111/111 [==============================] - 199s 2s/step - loss: 0.5154 - acc: 0.8055 - val_loss: 0.6225 - val_acc: 0.7873\n",
      "Epoch 34/112\n",
      "111/111 [==============================] - 199s 2s/step - loss: 0.5175 - acc: 0.8106 - val_loss: 0.6324 - val_acc: 0.7692\n",
      "Epoch 35/112\n",
      "111/111 [==============================] - 198s 2s/step - loss: 0.5175 - acc: 0.8095 - val_loss: 0.6214 - val_acc: 0.7598\n",
      "Epoch 36/112\n",
      "111/111 [==============================] - 198s 2s/step - loss: 0.4842 - acc: 0.8209 - val_loss: 0.6054 - val_acc: 0.7567\n",
      "Epoch 37/112\n",
      "111/111 [==============================] - 198s 2s/step - loss: 0.4861 - acc: 0.8166 - val_loss: 0.5971 - val_acc: 0.8023\n",
      "Epoch 38/112\n",
      "111/111 [==============================] - 200s 2s/step - loss: 0.4725 - acc: 0.8200 - val_loss: 0.5946 - val_acc: 0.7836\n",
      "Epoch 39/112\n",
      "111/111 [==============================] - 204s 2s/step - loss: 0.4891 - acc: 0.8236 - val_loss: 0.5809 - val_acc: 0.7805\n",
      "Epoch 40/112\n",
      "111/111 [==============================] - 200s 2s/step - loss: 0.4452 - acc: 0.8431 - val_loss: 0.6574 - val_acc: 0.7712\n",
      "Epoch 41/112\n",
      "111/111 [==============================] - 199s 2s/step - loss: 0.4418 - acc: 0.8379 - val_loss: 0.5463 - val_acc: 0.8126\n",
      "Epoch 42/112\n",
      "111/111 [==============================] - 199s 2s/step - loss: 0.4488 - acc: 0.8392 - val_loss: 0.6926 - val_acc: 0.7443\n",
      "Epoch 43/112\n",
      "111/111 [==============================] - 199s 2s/step - loss: 0.4393 - acc: 0.8467 - val_loss: 0.6206 - val_acc: 0.7774\n",
      "Epoch 44/112\n",
      "111/111 [==============================] - 215s 2s/step - loss: 0.4501 - acc: 0.8362 - val_loss: 0.6531 - val_acc: 0.7598\n",
      "Epoch 45/112\n",
      "111/111 [==============================] - 271s 2s/step - loss: 0.4259 - acc: 0.8482 - val_loss: 0.5702 - val_acc: 0.7743\n",
      "Epoch 46/112\n",
      "111/111 [==============================] - 229s 2s/step - loss: 0.4250 - acc: 0.8444 - val_loss: 0.5962 - val_acc: 0.7940\n",
      "Epoch 47/112\n",
      "111/111 [==============================] - 236s 2s/step - loss: 0.3877 - acc: 0.8593 - val_loss: 0.6582 - val_acc: 0.7754\n",
      "Epoch 48/112\n",
      "111/111 [==============================] - 234s 2s/step - loss: 0.3901 - acc: 0.8566 - val_loss: 0.5441 - val_acc: 0.8033\n",
      "Epoch 49/112\n",
      "111/111 [==============================] - 224s 2s/step - loss: 0.4006 - acc: 0.8549 - val_loss: 0.5470 - val_acc: 0.8033\n",
      "Epoch 50/112\n",
      "111/111 [==============================] - 216s 2s/step - loss: 0.3826 - acc: 0.8655 - val_loss: 0.6986 - val_acc: 0.7909\n",
      "Epoch 51/112\n",
      "111/111 [==============================] - 219s 2s/step - loss: 0.3645 - acc: 0.8685 - val_loss: 0.5486 - val_acc: 0.8095\n",
      "Epoch 52/112\n",
      "111/111 [==============================] - 245s 2s/step - loss: 0.3388 - acc: 0.8791 - val_loss: 0.5467 - val_acc: 0.7909\n",
      "Epoch 53/112\n",
      "111/111 [==============================] - 287s 3s/step - loss: 0.3343 - acc: 0.8778 - val_loss: 0.4865 - val_acc: 0.8344\n",
      "Epoch 54/112\n",
      "111/111 [==============================] - 263s 2s/step - loss: 0.3603 - acc: 0.8706 - val_loss: 0.6349 - val_acc: 0.7878\n",
      "Epoch 55/112\n",
      "111/111 [==============================] - 244s 2s/step - loss: 0.3266 - acc: 0.8814 - val_loss: 0.6321 - val_acc: 0.8033\n",
      "Epoch 56/112\n",
      "111/111 [==============================] - 251s 2s/step - loss: 0.3360 - acc: 0.8792 - val_loss: 0.5759 - val_acc: 0.8033\n",
      "Epoch 57/112\n",
      "111/111 [==============================] - 235s 2s/step - loss: 0.3228 - acc: 0.8799 - val_loss: 0.6068 - val_acc: 0.7992\n",
      "Epoch 58/112\n",
      "111/111 [==============================] - 217s 2s/step - loss: 0.3930 - acc: 0.8567 - val_loss: 0.5718 - val_acc: 0.8126\n",
      "Epoch 59/112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "111/111 [==============================] - 217s 2s/step - loss: 0.3224 - acc: 0.8825 - val_loss: 0.6148 - val_acc: 0.8178\n",
      "Epoch 60/112\n",
      "111/111 [==============================] - 218s 2s/step - loss: 0.3171 - acc: 0.8909 - val_loss: 0.6228 - val_acc: 0.7940\n",
      "Epoch 61/112\n",
      "111/111 [==============================] - 212s 2s/step - loss: 0.2999 - acc: 0.8975 - val_loss: 0.5980 - val_acc: 0.8116\n",
      "Epoch 62/112\n",
      "111/111 [==============================] - 197s 2s/step - loss: 0.3019 - acc: 0.8878 - val_loss: 0.6763 - val_acc: 0.8095\n",
      "Epoch 63/112\n",
      "111/111 [==============================] - 196s 2s/step - loss: 0.3024 - acc: 0.8964 - val_loss: 0.6991 - val_acc: 0.7774\n",
      "Epoch 64/112\n",
      "111/111 [==============================] - 197s 2s/step - loss: 0.3055 - acc: 0.8903 - val_loss: 0.6061 - val_acc: 0.8157\n",
      "Epoch 65/112\n",
      "111/111 [==============================] - 197s 2s/step - loss: 0.2702 - acc: 0.9011 - val_loss: 0.6416 - val_acc: 0.7933\n",
      "Epoch 66/112\n",
      "111/111 [==============================] - 198s 2s/step - loss: 0.2651 - acc: 0.9053 - val_loss: 0.6253 - val_acc: 0.8240\n",
      "Epoch 67/112\n",
      "111/111 [==============================] - 208s 2s/step - loss: 0.2759 - acc: 0.9063 - val_loss: 0.6594 - val_acc: 0.7940\n",
      "Epoch 68/112\n",
      "111/111 [==============================] - 209s 2s/step - loss: 0.3018 - acc: 0.9028 - val_loss: 0.5399 - val_acc: 0.8209\n",
      "Epoch 69/112\n",
      "111/111 [==============================] - 253s 2s/step - loss: 0.2627 - acc: 0.9090 - val_loss: 0.7267 - val_acc: 0.8054\n",
      "Epoch 70/112\n",
      "111/111 [==============================] - 252s 2s/step - loss: 0.2834 - acc: 0.9052 - val_loss: 0.6289 - val_acc: 0.8095\n",
      "Epoch 71/112\n",
      "111/111 [==============================] - 231s 2s/step - loss: 0.2745 - acc: 0.9101 - val_loss: 0.6666 - val_acc: 0.8054\n",
      "Epoch 72/112\n",
      "111/111 [==============================] - 211s 2s/step - loss: 0.2338 - acc: 0.9165 - val_loss: 0.6121 - val_acc: 0.8323\n",
      "Epoch 73/112\n",
      "111/111 [==============================] - 223s 2s/step - loss: 0.2219 - acc: 0.9214 - val_loss: 0.6148 - val_acc: 0.8271\n",
      "Epoch 74/112\n",
      "111/111 [==============================] - 207s 2s/step - loss: 0.2336 - acc: 0.9201 - val_loss: 0.6175 - val_acc: 0.8178\n",
      "Epoch 75/112\n",
      "111/111 [==============================] - 232s 2s/step - loss: 0.2593 - acc: 0.9209 - val_loss: 0.6961 - val_acc: 0.8219\n",
      "Epoch 76/112\n",
      "111/111 [==============================] - 279s 3s/step - loss: 0.2137 - acc: 0.9264 - val_loss: 0.5919 - val_acc: 0.8230\n",
      "Epoch 77/112\n",
      "111/111 [==============================] - 252s 2s/step - loss: 0.2499 - acc: 0.9124 - val_loss: 0.6634 - val_acc: 0.8178\n",
      "Epoch 78/112\n",
      "111/111 [==============================] - 222s 2s/step - loss: 0.2410 - acc: 0.9171 - val_loss: 0.7048 - val_acc: 0.7950\n",
      "Epoch 79/112\n",
      "111/111 [==============================] - 197s 2s/step - loss: 0.2415 - acc: 0.9150 - val_loss: 0.6878 - val_acc: 0.8282\n",
      "Epoch 80/112\n",
      "111/111 [==============================] - 197s 2s/step - loss: 0.2211 - acc: 0.9222 - val_loss: 0.6151 - val_acc: 0.8209\n",
      "Epoch 81/112\n",
      "111/111 [==============================] - 198s 2s/step - loss: 0.2277 - acc: 0.9135 - val_loss: 0.5864 - val_acc: 0.8323\n",
      "Epoch 82/112\n",
      "111/111 [==============================] - 198s 2s/step - loss: 0.1954 - acc: 0.9346 - val_loss: 0.8079 - val_acc: 0.8137\n",
      "Epoch 83/112\n",
      "111/111 [==============================] - 198s 2s/step - loss: 0.2786 - acc: 0.9061 - val_loss: 0.5998 - val_acc: 0.8261\n",
      "Epoch 84/112\n",
      "111/111 [==============================] - 198s 2s/step - loss: 0.1875 - acc: 0.9349 - val_loss: 0.8479 - val_acc: 0.7981\n",
      "Epoch 85/112\n",
      "111/111 [==============================] - 198s 2s/step - loss: 0.2233 - acc: 0.9227 - val_loss: 0.8173 - val_acc: 0.8147\n",
      "Epoch 86/112\n",
      "111/111 [==============================] - 198s 2s/step - loss: 0.2006 - acc: 0.9329 - val_loss: 0.6944 - val_acc: 0.8137\n",
      "Epoch 87/112\n",
      "111/111 [==============================] - 199s 2s/step - loss: 0.2290 - acc: 0.9273 - val_loss: 0.7091 - val_acc: 0.7847\n",
      "Epoch 88/112\n",
      "111/111 [==============================] - 198s 2s/step - loss: 0.2417 - acc: 0.9222 - val_loss: 0.7355 - val_acc: 0.8364\n",
      "Epoch 89/112\n",
      "111/111 [==============================] - 199s 2s/step - loss: 0.2326 - acc: 0.9192 - val_loss: 0.6635 - val_acc: 0.8023\n",
      "Epoch 90/112\n",
      "111/111 [==============================] - 197s 2s/step - loss: 0.2044 - acc: 0.9267 - val_loss: 0.6566 - val_acc: 0.8230\n",
      "Epoch 91/112\n",
      "111/111 [==============================] - 199s 2s/step - loss: 0.1826 - acc: 0.9331 - val_loss: 0.8152 - val_acc: 0.8157\n",
      "Epoch 92/112\n",
      "111/111 [==============================] - 200s 2s/step - loss: 0.2024 - acc: 0.9292 - val_loss: 0.6136 - val_acc: 0.8188\n",
      "Epoch 93/112\n",
      "111/111 [==============================] - 199s 2s/step - loss: 0.2551 - acc: 0.9171 - val_loss: 0.6415 - val_acc: 0.8230\n",
      "Epoch 94/112\n",
      "111/111 [==============================] - 198s 2s/step - loss: 0.2320 - acc: 0.9246 - val_loss: 0.6535 - val_acc: 0.8385\n",
      "Epoch 95/112\n",
      "111/111 [==============================] - 198s 2s/step - loss: 0.1765 - acc: 0.9405 - val_loss: 0.6705 - val_acc: 0.8313\n",
      "Epoch 96/112\n",
      "111/111 [==============================] - 198s 2s/step - loss: 0.1991 - acc: 0.9373 - val_loss: 0.6846 - val_acc: 0.8209\n",
      "Epoch 97/112\n",
      "111/111 [==============================] - 198s 2s/step - loss: 0.1547 - acc: 0.9520 - val_loss: 0.6689 - val_acc: 0.8377\n",
      "Epoch 98/112\n",
      "111/111 [==============================] - 199s 2s/step - loss: 0.2355 - acc: 0.9275 - val_loss: 0.6009 - val_acc: 0.8209\n",
      "Epoch 99/112\n",
      "111/111 [==============================] - 198s 2s/step - loss: 0.2166 - acc: 0.9327 - val_loss: 0.6933 - val_acc: 0.8137\n",
      "Epoch 100/112\n",
      "111/111 [==============================] - 198s 2s/step - loss: 0.1987 - acc: 0.9357 - val_loss: 0.6482 - val_acc: 0.8344\n",
      "Epoch 101/112\n",
      "111/111 [==============================] - 198s 2s/step - loss: 0.2123 - acc: 0.9245 - val_loss: 0.6472 - val_acc: 0.8271\n",
      "Epoch 102/112\n",
      "111/111 [==============================] - 199s 2s/step - loss: 0.1932 - acc: 0.9362 - val_loss: 0.7064 - val_acc: 0.8261\n",
      "Epoch 103/112\n",
      "111/111 [==============================] - 200s 2s/step - loss: 0.1876 - acc: 0.9346 - val_loss: 0.7363 - val_acc: 0.8116\n",
      "Epoch 104/112\n",
      "111/111 [==============================] - 198s 2s/step - loss: 0.1725 - acc: 0.9426 - val_loss: 0.7239 - val_acc: 0.8313\n",
      "Epoch 105/112\n",
      "111/111 [==============================] - 198s 2s/step - loss: 0.1682 - acc: 0.9445 - val_loss: 0.7051 - val_acc: 0.8209\n",
      "Epoch 106/112\n",
      "111/111 [==============================] - 199s 2s/step - loss: 0.1841 - acc: 0.9403 - val_loss: 0.7588 - val_acc: 0.8323\n",
      "Epoch 107/112\n",
      "111/111 [==============================] - 198s 2s/step - loss: 0.1885 - acc: 0.9389 - val_loss: 0.7923 - val_acc: 0.8137\n",
      "Epoch 108/112\n",
      "111/111 [==============================] - 199s 2s/step - loss: 0.1729 - acc: 0.9447 - val_loss: 0.7262 - val_acc: 0.8313\n",
      "Epoch 109/112\n",
      "111/111 [==============================] - 198s 2s/step - loss: 0.1655 - acc: 0.9524 - val_loss: 0.7754 - val_acc: 0.8354\n",
      "Epoch 110/112\n",
      "111/111 [==============================] - 199s 2s/step - loss: 0.2009 - acc: 0.9359 - val_loss: 0.6818 - val_acc: 0.8354\n",
      "Epoch 111/112\n",
      "111/111 [==============================] - 198s 2s/step - loss: 0.1788 - acc: 0.9419 - val_loss: 0.6050 - val_acc: 0.8313\n",
      "Epoch 112/112\n",
      "111/111 [==============================] - 198s 2s/step - loss: 0.1653 - acc: 0.9454 - val_loss: 0.9214 - val_acc: 0.8209\n",
      "Completed!!\n"
     ]
    }
   ],
   "source": [
    "model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch= nb_train_samples // batch_size,\n",
    "    epochs= epochs,\n",
    "    validation_data= validation_generator,\n",
    "    validation_steps= nb_validation_samples // batch_size)\n",
    "model.save_weights(\"SDA.hdf5\")\n",
    "print(\"Completed!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"sda.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
